{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"USE_TF\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataBench QA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question answer     type  \\\n",
      "0  Is the person with the highest net worth self-...   True  boolean   \n",
      "1    Does the youngest billionaire identify as male?   True  boolean   \n",
      "2  Is the city with the most billionaires in the ...   True  boolean   \n",
      "3  Is there a non-self-made billionaire in the to...   True  boolean   \n",
      "4  Does the oldest billionaire have a philanthrop...  False  boolean   \n",
      "\n",
      "                   columns_used                        column_types  \\\n",
      "0    ['finalWorth', 'selfMade']       ['number[uint32]', 'boolean']   \n",
      "1             ['age', 'gender']       ['number[UInt8]', 'category']   \n",
      "2           ['city', 'country']            ['category', 'category']   \n",
      "3          ['rank', 'selfMade']       ['number[uint16]', 'boolean']   \n",
      "4  ['age', 'philanthropyScore']  ['number[UInt8]', 'number[UInt8]']   \n",
      "\n",
      "  sample_answer     dataset  \n",
      "0         False  001_Forbes  \n",
      "1          True  001_Forbes  \n",
      "2          True  001_Forbes  \n",
      "3         False  001_Forbes  \n",
      "4         False  001_Forbes  \n",
      "Datasets referenced in QA pairs: ['001_Forbes' '002_Titanic' '003_Love' '004_Taxi' '005_NYC' '006_London'\n",
      " '007_Fifa' '008_Tornados' '009_Central' '010_ECommerce' '011_SF'\n",
      " '012_Heart' '013_Roller' '014_Airbnb' '015_Food' '016_Holiday'\n",
      " '017_Hacker' '018_Staff' '019_Aircraft' '020_Real' '021_Telco'\n",
      " '022_Airbnbs' '023_Climate' '024_Salary' '025_Data' '026_Predicting'\n",
      " '027_Supermarket' '028_Predict' '029_NYTimes' '030_Professionals'\n",
      " '031_Trustpilot' '032_Delicatessen' '033_Employee' '034_World'\n",
      " '035_Billboard' '036_US' '037_Ted' '038_Stroke' '039_Happy' '040_Speed'\n",
      " '041_Airline' '042_Predict' '043_Predict' '044_IMDb' '045_Predict'\n",
      " '046_120' '047_Bank' '048_Data' '049_Boris' '050_ING' '051_Pokemon'\n",
      " '052_Professional' '053_Patents' '054_Joe' '055_German' '056_Emoji'\n",
      " '057_Spain' '058_US' '059_Second' '060_Bakery' '061_Disneyland'\n",
      " '062_Trump' '063_Influencers' '064_Clustering' '065_RFM']\n"
     ]
    }
   ],
   "source": [
    "# Load all QA pairs\n",
    "all_qa = load_dataset(\"cardiffnlp/databench\", name=\"qa\", split=\"train\")\n",
    "\n",
    "# Convert to a pandas DataFrame for easier manipulation\n",
    "qa_df = pd.DataFrame(all_qa)\n",
    "\n",
    "# View the first few rows\n",
    "print(qa_df.head())\n",
    "\n",
    "# Check the dataset names\n",
    "dataset_names = qa_df['dataset'].unique()\n",
    "print(f\"Datasets referenced in QA pairs: {dataset_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Load Dataset by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_by_id(ds_id, version='all'):\n",
    "    \"\"\"\n",
    "    Loads a dataset by its ID from the Hugging Face Hub.\n",
    "\n",
    "    Args:\n",
    "        ds_id (str): The dataset ID (e.g., '001_Forbes').\n",
    "        version (str): 'all' for full dataset, 'sample' for sampled version.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded dataset as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet(f\"hf://datasets/cardiffnlp/databench/data/{ds_id}/{version}.parquet\")\n",
    "        print(f\"Loaded dataset '{ds_id}' ({version} version).\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset {ds_id}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess a Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset '001_Forbes' (all version).\n",
      "   rank                personName   age  finalWorth               category  \\\n",
      "0     1                 Elon Musk  50.0      219000             Automotive   \n",
      "1     2                Jeff Bezos  58.0      171000             Technology   \n",
      "2     3  Bernard Arnault & family  73.0      158000       Fashion & Retail   \n",
      "3     4                Bill Gates  66.0      129000             Technology   \n",
      "4     5            Warren Buffett  91.0      118000  Finance & Investments   \n",
      "\n",
      "               source        country       state     city  \\\n",
      "0       Tesla, SpaceX  United States       Texas   Austin   \n",
      "1              Amazon  United States  Washington  Seattle   \n",
      "2                LVMH         France         NaN    Paris   \n",
      "3           Microsoft  United States  Washington   Medina   \n",
      "4  Berkshire Hathaway  United States    Nebraska    Omaha   \n",
      "\n",
      "                       organization  selfMade gender  \\\n",
      "0                             Tesla      True      M   \n",
      "1                            Amazon      True      M   \n",
      "2  LVMH Moët Hennessy Louis Vuitton     False      M   \n",
      "3   Bill & Melinda Gates Foundation      True      M   \n",
      "4                Berkshire Hathaway      True      M   \n",
      "\n",
      "                  birthDate             title  philanthropyScore  \\\n",
      "0 1971-06-28 00:00:00+00:00               CEO                1.0   \n",
      "1 1964-01-12 00:00:00+00:00      Entrepreneur                1.0   \n",
      "2 1949-03-05 00:00:00+00:00  Chairman and CEO                NaN   \n",
      "3 1955-10-28 00:00:00+00:00         Cofounder                4.0   \n",
      "4 1930-08-30 00:00:00+00:00               CEO                5.0   \n",
      "\n",
      "                                                 bio  \\\n",
      "0  Elon Musk is working to revolutionize transpor...   \n",
      "1  Jeff Bezos founded e-commerce giant Amazon in ...   \n",
      "2  Bernard Arnault oversees the LVMH empire of so...   \n",
      "3  Bill Gates turned his fortune from software fi...   \n",
      "4  Known as the \"Oracle of Omaha,\" Warren Buffett...   \n",
      "\n",
      "                                               about  \n",
      "0  Musk was accepted to a graduate program at Sta...  \n",
      "1  Growing up, Jeff Bezos worked summers on his g...  \n",
      "2  Arnault apparently wooed his wife, Helene Merc...  \n",
      "3  When Gates was a kid, he spent so much time re...  \n",
      "4  Buffett still lives in the same Omaha, Nebrask...  \n"
     ]
    }
   ],
   "source": [
    "# Load the first dataset referenced in the QA pairs\n",
    "ds_id = qa_df['dataset'][0]  # e.g., '001_Forbes'\n",
    "\n",
    "# Load the full version of the dataset\n",
    "df_full = load_dataset_by_id(ds_id, version='all')\n",
    "\n",
    "# Check if the dataset was loaded successfully\n",
    "if df_full is not None:\n",
    "    # Display the first few rows\n",
    "    print(df_full.head())\n",
    "else:\n",
    "    print(\"Dataset could not be loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_table(table):\n",
    "    \"\"\"\n",
    "    Preprocesses the table by handling missing values and any other required preprocessing steps.\n",
    "\n",
    "    Args:\n",
    "        table (pd.DataFrame): The input table.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed table.\n",
    "    \"\"\"\n",
    "    # Convert categorical columns to strings\n",
    "    for col in table.select_dtypes(include=['category']).columns:\n",
    "        table[col] = table[col].astype(str)\n",
    "\n",
    "    # Fill missing values\n",
    "    table = table.fillna(\"Unknown\")\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Loaded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank                personName   age  finalWorth               category  \\\n",
      "0     1                 Elon Musk  50.0      219000             Automotive   \n",
      "1     2                Jeff Bezos  58.0      171000             Technology   \n",
      "2     3  Bernard Arnault & family  73.0      158000       Fashion & Retail   \n",
      "3     4                Bill Gates  66.0      129000             Technology   \n",
      "4     5            Warren Buffett  91.0      118000  Finance & Investments   \n",
      "\n",
      "               source        country       state     city  \\\n",
      "0       Tesla, SpaceX  United States       Texas   Austin   \n",
      "1              Amazon  United States  Washington  Seattle   \n",
      "2                LVMH         France         nan    Paris   \n",
      "3           Microsoft  United States  Washington   Medina   \n",
      "4  Berkshire Hathaway  United States    Nebraska    Omaha   \n",
      "\n",
      "                       organization  selfMade gender  \\\n",
      "0                             Tesla      True      M   \n",
      "1                            Amazon      True      M   \n",
      "2  LVMH Moët Hennessy Louis Vuitton     False      M   \n",
      "3   Bill & Melinda Gates Foundation      True      M   \n",
      "4                Berkshire Hathaway      True      M   \n",
      "\n",
      "                   birthDate             title philanthropyScore  \\\n",
      "0  1971-06-28 00:00:00+00:00               CEO               1.0   \n",
      "1  1964-01-12 00:00:00+00:00      Entrepreneur               1.0   \n",
      "2  1949-03-05 00:00:00+00:00  Chairman and CEO           Unknown   \n",
      "3  1955-10-28 00:00:00+00:00         Cofounder               4.0   \n",
      "4  1930-08-30 00:00:00+00:00               CEO               5.0   \n",
      "\n",
      "                                                 bio  \\\n",
      "0  Elon Musk is working to revolutionize transpor...   \n",
      "1  Jeff Bezos founded e-commerce giant Amazon in ...   \n",
      "2  Bernard Arnault oversees the LVMH empire of so...   \n",
      "3  Bill Gates turned his fortune from software fi...   \n",
      "4  Known as the \"Oracle of Omaha,\" Warren Buffett...   \n",
      "\n",
      "                                               about  \n",
      "0  Musk was accepted to a graduate program at Sta...  \n",
      "1  Growing up, Jeff Bezos worked summers on his g...  \n",
      "2  Arnault apparently wooed his wife, Helene Merc...  \n",
      "3  When Gates was a kid, he spent so much time re...  \n",
      "4  Buffett still lives in the same Omaha, Nebrask...  \n"
     ]
    }
   ],
   "source": [
    "if df_full is not None:\n",
    "    # Preprocess the loaded dataset\n",
    "    df_preprocessed = preprocess_table(df_full)\n",
    "\n",
    "    # Display the first few rows\n",
    "    print(df_preprocessed.head())\n",
    "else:\n",
    "    print(\"Cannot preprocess because the dataset was not loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Get Answer Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_coordinates(table, answer_text):\n",
    "    \"\"\"\n",
    "    Generates the coordinates of the answer in the table.\n",
    "\n",
    "    Args:\n",
    "        table (pd.DataFrame): The table where the answer is located.\n",
    "        answer_text (str): The answer text.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, int]]: List of (row_index, column_index) tuples.\n",
    "    \"\"\"\n",
    "    coordinates = []\n",
    "    for row_idx, row in table.iterrows():\n",
    "        for col_idx, value in enumerate(row):\n",
    "            if str(value).lower() == str(answer_text).lower():\n",
    "                coordinates.append((row_idx, col_idx))\n",
    "    return coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DataBenchQADataset(Dataset):\n",
    "    def __init__(self, qa_df, tokenizer):\n",
    "        self.qa_df = qa_df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qa_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = idx\n",
    "        max_attempts = len(self.qa_df)\n",
    "        attempts = 0\n",
    "\n",
    "        while attempts < max_attempts:\n",
    "            row = self.qa_df.iloc[idx]\n",
    "            dataset_id = row['dataset']\n",
    "            question = row['question']\n",
    "            answer_text = row['answer']\n",
    "\n",
    "            # Load the corresponding table\n",
    "            table = load_dataset_by_id(dataset_id, version='all')\n",
    "            if table is None:\n",
    "                # Skip to next example\n",
    "                idx = (idx + 1) % len(self.qa_df)\n",
    "                attempts += 1\n",
    "                continue\n",
    "\n",
    "            # Preprocess the table\n",
    "            table = preprocess_table(table)\n",
    "\n",
    "            # Generate answer coordinates\n",
    "            answer_coordinates = get_answer_coordinates(table, answer_text)\n",
    "            if not answer_coordinates:\n",
    "                # Skip to next example\n",
    "                idx = (idx + 1) % len(self.qa_df)\n",
    "                attempts += 1\n",
    "                continue\n",
    "\n",
    "            # Prepare inputs\n",
    "            inputs = self.tokenizer(\n",
    "                table=table,\n",
    "                queries=question,\n",
    "                answer_coordinates=[answer_coordinates],\n",
    "                answer_text=[answer_text],\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            # Remove batch dimension\n",
    "            for k in inputs:\n",
    "                inputs[k] = inputs[k].squeeze(0)\n",
    "\n",
    "            return inputs\n",
    "\n",
    "        # If no valid example is found after max_attempts\n",
    "        raise ValueError(\"No valid examples found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Tokenizer and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\saadg\\.cache\\huggingface\\hub\\models--google--tapas-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TapasTokenizer.from_pretrained('google/tapas-base')\n",
    "\n",
    "# Initialize the dataset\n",
    "train_dataset = DataBenchQADataset(qa_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune the TAPAS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[0;32m     44\u001b[0m     hp_params,\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TapasForQuestionAnswering, TrainingArguments, Trainer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m TapasForQuestionAnswering\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle/tapas-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\saadg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "from transformers import TapasForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "# Initialize the model\n",
    "model = TapasForQuestionAnswering.from_pretrained('google/tapas-base')\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate=1e-5,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Since we don't have a validation dataset, we'll split the training data\n",
    "split = int(0.9 * len(train_dataset))\n",
    "train_subset = torch.utils.data.Subset(train_dataset, range(0, split))\n",
    "eval_subset = torch.utils.data.Subset(train_dataset, range(split, len(train_dataset)))\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=eval_subset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained('fine-tuned-tapas')\n",
    "tokenizer.save_pretrained('fine-tuned-tapas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the fine-tuned model and tokenizer\n",
    "# tokenizer = TapasTokenizer.from_pretrained('fine-tuned-tapas')\n",
    "# model = TapasForQuestionAnswering.from_pretrained('fine-tuned-tapas')\n",
    "\n",
    "# # Example question and dataset\n",
    "# test_idx = 0  # Index of the test example\n",
    "# test_row = qa_df.iloc[test_idx]\n",
    "# test_dataset_id = test_row['dataset']\n",
    "# test_question = test_row['question']\n",
    "# test_answer = test_row['answer']\n",
    "\n",
    "# # Load and preprocess the dataset\n",
    "# test_table = load_dataset_by_id(test_dataset_id, version='all')\n",
    "# test_table = preprocess_table(test_table)\n",
    "\n",
    "# # Prepare inputs\n",
    "# inputs = tokenizer(\n",
    "#     table=test_table,\n",
    "#     queries=test_question,\n",
    "#     padding='max_length',\n",
    "#     truncation=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# )\n",
    "\n",
    "# # Get model outputs\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "# # Get the predicted answer coordinates\n",
    "# predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "#     inputs,\n",
    "#     outputs.logits,\n",
    "#     outputs.logits_aggregation\n",
    "# )\n",
    "\n",
    "# # Extract the answers from the table\n",
    "# answers = []\n",
    "# for coordinates in predicted_answer_coordinates:\n",
    "#     cell_values = []\n",
    "#     for coord in coordinates:\n",
    "#         try:\n",
    "#             cell_value = test_table.iat[coord]\n",
    "#             cell_values.append(str(cell_value))\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error accessing cell at {coord}: {e}\")\n",
    "#             continue\n",
    "#     answers.append(\", \".join(cell_values))\n",
    "\n",
    "# # Handle aggregation (if any)\n",
    "# aggregation_ops = ['NONE', 'SUM', 'AVERAGE', 'COUNT']\n",
    "# agg_op_idx = predicted_aggregation_indices[0]\n",
    "# agg_op = aggregation_ops[agg_op_idx]\n",
    "\n",
    "# if agg_op == 'NONE':\n",
    "#     answer = \", \".join(answers)\n",
    "# elif agg_op == 'SUM':\n",
    "#     nums = [float(a) for a in answers if a.replace('.', '', 1).isdigit()]\n",
    "#     answer = str(sum(nums)) if nums else \"0\"\n",
    "# elif agg_op == 'AVERAGE':\n",
    "#     nums = [float(a) for a in answers if a.replace('.', '', 1).isdigit()]\n",
    "#     answer = str(sum(nums) / len(nums)) if nums else \"0\"\n",
    "# elif agg_op == 'COUNT':\n",
    "#     answer = str(len(answers))\n",
    "# else:\n",
    "#     answer = \", \".join(answers)\n",
    "\n",
    "# print(f\"Question: {test_question}\")\n",
    "# print(f\"Predicted Answer: {answer}\")\n",
    "# print(f\"Actual Answer: {test_answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
